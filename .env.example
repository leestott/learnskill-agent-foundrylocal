# Foundry Local Configuration
# The endpoint is auto-discovered, but you can override it here
FOUNDRY_LOCAL_ENDPOINT=http://localhost:5273

# Default model to use for local inference
FOUNDRY_LOCAL_MODEL=phi-4

# Microsoft Foundry (Cloud) Configuration
# Get these from your Microsoft Foundry project at https://ai.azure.com
# Navigate to your project > Deployments > select model > copy endpoint & key
FOUNDRY_CLOUD_ENDPOINT=https://your-project.services.foundry.microsoft.com
FOUNDRY_CLOUD_API_KEY=your-api-key-here
FOUNDRY_CLOUD_MODEL=gpt-4o-mini

# GitHub Token (optional - for cloning private repos)
# GITHUB_TOKEN=your_github_token

# Output directory for generated docs (defaults to ./docs in target repo)
OUTPUT_DIR=./docs
